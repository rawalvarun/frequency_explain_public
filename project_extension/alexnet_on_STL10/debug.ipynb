{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "Python 3.7.6 64-bit ('base': conda)",
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "metadata": {
        "interpreter": {
          "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
      }
    },
    "colab": {
      "name": "debug.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYnd04doIfp",
        "outputId": "00872b07-31c3-4351-e8d3-6421ccddc643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install advertorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: advertorch in /opt/conda/lib/python3.7/site-packages (0.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCWx_ZODwxu"
      },
      "source": [
        "\n",
        "####################################\n",
        "# imshow func\n",
        "####################################\n",
        "def imshow(img):\n",
        "\timg = img / 2 + 0.5     # unnormalize\n",
        "\tnpimg = img.numpy()\n",
        "\tplt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def _imshow(img):\n",
        "\timshow(torchvision.utils.make_grid(img, normalize=True))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "8SIVXNUUn127",
        "outputId": "9c3994a4-4656-44ca-c41c-f93cddfa8c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "\n",
        "# coding: utf-8\n",
        "\n",
        "# # Table of Contents\n",
        "#  <p>\n",
        "\n",
        "# In[1]:\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from advertorch.attacks import LinfPGDAttack, CarliniWagnerL2Attack, JacobianSaliencyMapAttack, LBFGSAttack\n",
        "\n",
        "# \t\t\t\t\t\t\t\tPGD Attack, \tCW Attack, \t\t\tJacobian Attack,\t\t\tFGSM Attack\n",
        "\n",
        "\n",
        "# import vgg\n",
        "# from vgg import VGG\n",
        "from scipy.fftpack import dct, idct\n",
        "\n",
        "from robustness.datasets import CIFAR\n",
        "from robustness.model_utils import make_and_restore_model\n",
        "\n",
        "# set whether to use GPU\n",
        "torch.manual_seed(0)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "def DCT(image):\n",
        "\treturn dct(dct(image, norm=\"ortho\", axis=0), norm=\"ortho\", axis=1)\n",
        "def iDCT(image):\n",
        "\treturn idct(idct(image, norm=\"ortho\", axis=0), norm=\"ortho\", axis=1)\n",
        "\n",
        "class MMD_loss(nn.Module):\n",
        "\tdef __init__(self, kernel_mul = 2.0, kernel_num = 5):\n",
        "\t\tsuper(MMD_loss, self).__init__()\n",
        "\t\tself.kernel_num = kernel_num\n",
        "\t\tself.kernel_mul = kernel_mul\n",
        "\t\tself.fix_sigma = None\n",
        "\t\treturn\n",
        "\t\n",
        "\tdef guassian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
        "\t\tn_samples = int(source.size()[0])+int(target.size()[0])\n",
        "\t\ttotal = torch.cat([source, target], dim=0)\n",
        "\t\ttotal0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
        "\t\ttotal1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
        "\t\tL2_distance = ((total0-total1)**2).sum(2) \n",
        "\t\t\n",
        "\t\tif fix_sigma:\n",
        "\t\t\tbandwidth = fix_sigma\n",
        "\t\telse:\n",
        "\t\t\tbandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
        "\t\t\t\n",
        "\t\tbandwidth /= kernel_mul ** (kernel_num // 2)\n",
        "\t\tbandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
        "\t\tkernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
        "\t\treturn sum(kernel_val)\n",
        "\n",
        "\tdef forward(self, source, target):\n",
        "\t\tbatch_size = int(source.size()[0])\n",
        "\t\tkernels = self.guassian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
        "\t\tXX = kernels[:batch_size, :batch_size]\n",
        "\t\tYY = kernels[batch_size:, batch_size:]\n",
        "\t\tXY = kernels[:batch_size, batch_size:]\n",
        "\t\tYX = kernels[batch_size:, :batch_size]\n",
        "\t\tloss = torch.mean(XX + YY - XY -YX)\n",
        "\t\treturn loss\n",
        "\t\n",
        "def lscale01(M):\n",
        "\n",
        "\tNew_M = np.zeros((M.shape))\n",
        "\tMIN = np.min(M)\n",
        "\tMAX = np.max(M)\n",
        "\tif (MAX == MIN):\n",
        "\t\tNew_M[:, :] = 0.0 * M\n",
        "\telse:\n",
        "\t\tNew_M[:, :] = (M - MIN) / (MAX - MIN)\n",
        "\n",
        "\treturn New_M\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "####################################\n",
        "# model dir\n",
        "####################################\n",
        "if use_cuda:\n",
        "\tMODEL = \"model.pkl\"\n",
        "else:\n",
        "\tMODEL = \"model.pkl\"\n",
        "\n",
        "\n",
        "####################################\n",
        "# load model\n",
        "####################################\n",
        "\n",
        "# Set the model \n",
        "model = vgg.vgg19()\n",
        "\n",
        "if os.path.isfile(MODEL):\n",
        "\tprint(\"=> loading model '{}'\".format(MODEL))\n",
        "\tif use_cuda:\n",
        "\t\tmodel = torch.load(MODEL)['net']\n",
        "\t\tmodel.to(device)\n",
        "\telse:\n",
        "\t\tmodel = torch.load(MODEL, map_location=device)['net']\n",
        "\tprint('model loaded')\n",
        "else:\n",
        "\tprint(\"=> no checkpoint found at '{}'\".format(MODEL))\n",
        "'''\n",
        "\n",
        "\n",
        "# from CPU_utils import make_and_restore_model_CPU_only\n",
        "\n",
        "# MODEL = \"cifar_nat.pt\"\n",
        "\n",
        "# ds = CIFAR('data/cifar-10-batches-py')\n",
        "\n",
        "# if use_cuda:\n",
        "# \tmodel, _ = make_and_restore_model(arch='resnet50', dataset=ds,\n",
        "# \t\t\tresume_path=MODEL, parallel=False)\n",
        "# else:\n",
        "# \tmodel, _ = make_and_restore_model_CPU_only(arch='resnet50', dataset=ds,\n",
        "# \t\t\t\tresume_path=MODEL, parallel=False)\n",
        "\n",
        "# model = model.model\n",
        "# model.eval()\n",
        "\n",
        "\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "# resnet18 = models.resnet18(pretrained=True)\n",
        "# vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "# squeezenet = models.squeezenet1_0(pretrained=True)\n",
        "# densenet = models.densenet161(pretrained=True)\n",
        "# inception = models.inception_v3(pretrained=True)\n",
        "# googlenet = models.googlenet(pretrained=True)\n",
        "# shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "# mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "# resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
        "# wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
        "# mnasnet = models.mnasnet1_0(pretrained=True)\n",
        "\n",
        "model = alexnet\n",
        "\n",
        "\n",
        "# pick from transfer_learnt model\n",
        "model = torch.load(\"saved_alexnet_transfer_learnt_10classes.pth\")\n",
        "# important before starting inferencing\n",
        "model.eval()\n",
        "\n",
        "####################################\n",
        "# load data\n",
        "####################################\n",
        "batch_size = 200\n",
        "num_folds = 0\n",
        "\n",
        "transform=transforms.Compose([\n",
        "                    transforms.Pad(4),\n",
        "                    transforms.RandomCrop(96),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                ])\n",
        "\n",
        "testset = torchvision.datasets.STL10(root='../data',download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=0)\n",
        "\n",
        "classes =  ('airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "####################################\n",
        "# Construct an adversary instance\n",
        "####################################\n",
        "adversary_CW = CarliniWagnerL2Attack(model, num_classes = len(classes) , \n",
        "\tconfidence=0, targeted=False, learning_rate=0.01, binary_search_steps=9, max_iterations=10000, \n",
        "\tabort_early=True, initial_const=0.001, clip_min=0.0, clip_max=1.0, loss_fn=None)\n",
        "\n",
        "adversary_Jacobian = JacobianSaliencyMapAttack(model, num_classes = len(classes), \n",
        "\tclip_min=0.0, clip_max=1.0, loss_fn=None, theta=1.0, gamma=1.0, comply_cleverhans=False)\n",
        "\n",
        "adversary_PGD = LinfPGDAttack(\n",
        "\tmodel, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"), eps=0.15,\n",
        "\tnb_iter=40, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0,\n",
        "\ttargeted=False)\n",
        "\n",
        "adversary_FGSM = LBFGSAttack(model, num_classes = len(classes), batch_size=1, binary_search_steps=9, \n",
        "\tmax_iterations=100, initial_const=0.01, clip_min=0, clip_max=1, loss_fn=None, targeted=False)\n",
        "\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "# Set the type of attack\n",
        "\n",
        "loss = MMD_loss()\n",
        "\n",
        "\n",
        "# adversary = adversary_CW\n",
        "# FOLDER = 'adversary_CW/'\n",
        "\n",
        "\n",
        "\n",
        "adversary = adversary_PGD\n",
        "FOLDER = './adversary_PGD/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "filetxt = FOLDER+'output.txt'\n",
        "if not os.path.exists(FOLDER):\n",
        "\tos.makedirs(FOLDER)\n",
        "\n",
        "true = np.zeros((0)).astype(int)\n",
        "pred_cln = np.zeros((0)).astype(int)\n",
        "pred_untargeted_adv = np.zeros((0)).astype(int)\n",
        "pred_targeted_adv = np.zeros((0)).astype(int)\n",
        "\n",
        "MMD_untargeted = np.zeros((0))\n",
        "MMD_targeted = np.zeros((0))\n",
        "\n",
        "\n",
        "fold = 0\n",
        "DCT_untargeted = 0\n",
        "DCT_targeted = 0\n",
        "\t"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UKU6LEcn13M",
        "outputId": "020a19a0-34f2-431a-d3b8-e6168d318ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cln_data, true_label = next(iter(testloader))\n",
        "\n",
        "_, pred_cln_ = torch.max(model(cln_data), 1)\n",
        "\n",
        "cln_data\n",
        "\n",
        "pred_cln_"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 4, 6, 4, 9, 4, 4, 5, 8, 0, 6, 5, 8, 7, 6, 6, 6, 2, 2, 4, 1, 6, 2,\n",
              "        1, 8, 6, 1, 5, 7, 0, 0, 2, 1, 3, 6, 5, 2, 5, 7, 0, 6, 1, 3, 7, 4, 3, 0,\n",
              "        6, 7, 6, 5, 8, 0, 6, 1, 6, 6, 8, 2, 2, 2, 9, 5, 1, 7, 8, 5, 8, 8, 9, 0,\n",
              "        5, 2, 2, 1, 6, 7, 8, 9, 5, 0, 8, 3, 2, 6, 6, 6, 8, 3, 5, 9, 6, 6, 6, 7,\n",
              "        0, 5, 0, 5, 2, 7, 1, 0, 0, 8, 0, 4, 2, 4, 3, 2, 5, 5, 1, 2, 6, 6, 2, 2,\n",
              "        8, 9, 5, 7, 0, 5, 1, 3, 6, 3, 6, 4, 8, 5, 1, 3, 7, 4, 6, 2, 9, 5, 2, 2,\n",
              "        2, 8, 8, 6, 1, 6, 8, 2, 0, 3, 2, 3, 5, 7, 8, 7, 2, 2, 7, 8, 9, 8, 2, 7,\n",
              "        4, 3, 5, 6, 7, 7, 6, 9, 1, 2, 2, 7, 9, 4, 1, 0, 4, 4, 2, 4, 4, 6, 5, 3,\n",
              "        4, 1, 3, 5, 4, 2, 0, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTyMzxlzn13V",
        "outputId": "7770008f-7248-420f-b380-4c55ca64a2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "alexnet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRkL4XGkn13j",
        "outputId": "22d538ca-1b0b-4e2a-bd72-30f6c4b30901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "if use_cuda:\n",
        "\tcln_data = cln_data.cuda()\n",
        "\ttrue_label = true_label.cuda()\n",
        "\tmodel = model.cuda()\n",
        "\t\n",
        "\n",
        "for cln_data, true_label in testloader:\n",
        "\n",
        "\tprint(\"working for fold number :\", fold,\"\\n\")\n",
        "\n",
        "\tcln_data, true_label = cln_data.to(device), true_label.to(device)   \n",
        "\tmodel = model.to(device)\n",
        "\ttrue = np.concatenate((true, true_label.cpu().numpy().astype(int)), axis=None)\n",
        "\t\n",
        "\t_, pred_cln_ = torch.max(model(cln_data), 1)\n",
        "\tpred_cln = np.concatenate((pred_cln, pred_cln_.cpu().numpy().astype(int)), axis=None)\n",
        "\n",
        "\t# select only good samples for showcasing\n",
        "\tcompare_prediction_label = (pred_cln == true)\n",
        "\tgood_samples = [i for i, x in enumerate(compare_prediction_label) if x == True]    \n",
        "\t\n",
        "\t####################################\n",
        "\t#Perform untargeted attack\t\n",
        "\t####################################\n",
        "\t\n",
        "\tprint(\"starting untargeted attack\")\n",
        "\tadv_untargeted = adversary.perturb(cln_data, true_label)\n",
        "\tprint(\"Completed untargeted attack !\")\n",
        "\n",
        "\n",
        "\t_, pred_untargeted_adv_ = torch.max(model(adv_untargeted), 1)\n",
        "\tpred_untargeted_adv = np.concatenate((pred_untargeted_adv, pred_untargeted_adv_.cpu().numpy().astype(int)), axis=None)\n",
        "\t\n",
        "\t####################################\n",
        "\t# perform targeted attack\n",
        "\t####################################\n",
        "\ttarget = torch.ones_like(true_label) * 3\n",
        "\tadversary.targeted = True\n",
        "\t\n",
        "\n",
        "\tprint(\"starting targeted attack ...\")\n",
        "\tadv_targeted = adversary.perturb(cln_data, target)\n",
        "\tprint(\"Completed untargeted attack !\")\n",
        "\t\n",
        "\t_, pred_adv_targeted_ = torch.max(model(adv_targeted), 1)\n",
        "\tpred_targeted_adv = np.concatenate((pred_targeted_adv, pred_adv_targeted_.cpu().numpy().astype(int)), axis=None)\n",
        "\n",
        "\tfor i in range(len(true_label)):\n",
        "\t\timage = np.transpose(adv_untargeted[i].cpu().numpy(), (1, 2, 0))\n",
        "\t\tdct_adv_untargeted = ((DCT(image[:,:,0]) + DCT(image[:,:,1]) + DCT(image[:,:,2]))/3.0)\n",
        "\n",
        "\t\timage = np.transpose(adv_targeted[i].cpu().numpy(), (1, 2, 0))\n",
        "\t\tdct_adv_targeted = ((DCT(image[:,:,0]) + DCT(image[:,:,1]) + DCT(image[:,:,2]))/3.0)\n",
        "\n",
        "\t\timage = np.transpose(cln_data[i].cpu().numpy(), (1, 2, 0))\n",
        "\t\tdct_image = ((DCT(image[:,:,0]) + DCT(image[:,:,1]) + DCT(image[:,:,2]))/3.0)\n",
        "\n",
        "\t\tDCT_untargeted = DCT_untargeted + abs((dct_image - dct_adv_untargeted)/dct_image)\n",
        "\t\tDCT_targeted = DCT_targeted + abs((dct_image - dct_adv_targeted)/dct_image)\n",
        "\n",
        "\t\tMMD_targeted = np.append(MMD_targeted,loss(torch.from_numpy(dct_adv_targeted), torch.from_numpy(dct_image)).cpu().item())\n",
        "\t\tMMD_untargeted = np.append(MMD_untargeted,loss(torch.from_numpy(dct_adv_untargeted), torch.from_numpy(dct_image)).cpu().item())\n",
        "\tfold += 1\n",
        "\tif(fold > num_folds):\n",
        "\t\tbreak\n",
        "\t"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working for fold number : 1 \n",
            "\n",
            "starting untargeted attack\n",
            "Completed untargeted attack !\n",
            "starting targeted attack ...\n",
            "Completed untargeted attack !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5MrPDXAn13s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84RU_q6In131",
        "outputId": "411f736b-2a6f-4731-f5cf-827783d0d81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\t\n",
        "####################################\n",
        "# Visualization of attacks\n",
        "####################################\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc_adv_untargeted = 100*np.mean(true == pred_untargeted_adv)\n",
        "acc_adv_targeted = 100*np.mean(true == pred_targeted_adv)\n",
        "acc_cln = 100*np.mean(true == pred_cln)\n",
        "\n",
        "print('Total Accuracy: ',\"Unattacked: \", acc_cln, \n",
        "\t  '\\t and during attack: ',FOLDER,'\\t',\n",
        "\t  \n",
        "\t  \"Untargeted attack: \",acc_adv_untargeted,\n",
        "\t  \"\\tTargeted attack: \",acc_adv_targeted,\n",
        "\t file=open(filetxt, \"a\"))\n",
        "\n",
        "correct_pred_indx = (true == pred_cln)\n",
        "acc_adv_untargeted = 100*np.mean(true[correct_pred_indx] == pred_untargeted_adv[correct_pred_indx])\n",
        "acc_adv_targeted = 100*np.mean(true[correct_pred_indx] == pred_targeted_adv[correct_pred_indx])\n",
        "print('Effect of attack on accurately predcited image by unattacked model:\\t'      \n",
        "\t  \"Untargeted attack: \",acc_adv_untargeted,\n",
        "\t  \"\\tTargeted attack: \",acc_adv_targeted,\n",
        "\t file=open(filetxt, \"a\"))\n",
        "\n",
        "DCT_untargeted = (DCT_untargeted/len(true))\n",
        "DCT_targeted = (DCT_targeted/len(true))\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(6, 6))\n",
        "im1 = ax.imshow(lscale01(DCT_untargeted), cmap='YlOrRd')\n",
        "ax.title.set_text('untargeted')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)    \n",
        "fig.colorbar(im1, cax=cax)\n",
        "# ax.set_axis_off()\n",
        "plt.savefig(FOLDER+'correct_DCT_untargeted.png')\n",
        "# plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(6, 6))\n",
        "im1 = ax.imshow(lscale01(DCT_targeted), cmap='YlOrRd')\n",
        "ax.title.set_text('targeted')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)    \n",
        "fig.colorbar(im1, cax=cax)\n",
        "# ax.set_axis_off()\n",
        "plt.savefig(FOLDER+'correct_DCT_targeted.png')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "c_indx_untargeted = np.logical_and(true == pred_cln,true == pred_untargeted_adv)\n",
        "c_indx_targeted = np.logical_and(true == pred_cln,true == pred_targeted_adv)\n",
        "\n",
        "true_pred_untargeted = np.sum(c_indx_untargeted)/np.sum(correct_pred_indx)\n",
        "true_pred_targeted = np.sum(c_indx_targeted)/np.sum(correct_pred_indx)\n",
        "\n",
        "w_indx_untargeted = np.logical_and(true == pred_cln,true != pred_untargeted_adv)\n",
        "w_indx_targeted = np.logical_and(true == pred_cln,true != pred_targeted_adv)\n",
        "\n",
        "false_pred_untargeted = np.sum(w_indx_untargeted)/np.sum(correct_pred_indx)\n",
        "false_pred_targeted = np.sum(w_indx_targeted)/np.sum(correct_pred_indx)\n",
        "\n",
        "print(\"True pred accuracy of samples: \",100*true_pred_untargeted,100*true_pred_targeted,\n",
        "\t file=open(filetxt, \"a\"))\n",
        "print(\"wrong pred accuracy of samples: \",100*false_pred_untargeted,100*false_pred_targeted,\n",
        "\t file=open(filetxt, \"a\"))\n",
        "\n",
        "print(\"Total mean MMD: \", np.mean(MMD_untargeted), \n",
        "\t  np.mean(MMD_targeted),\n",
        "\t file=open(filetxt, \"a\"))\n",
        "print(\"Correct mean MMD: \", np.mean(MMD_untargeted[c_indx_untargeted]), \n",
        "\t  np.mean(MMD_targeted[c_indx_targeted]),\n",
        "\t file=open(filetxt, \"a\"))\n",
        "print(\"wrong mean MMD: \", np.mean(MMD_untargeted[w_indx_untargeted == 0]), \n",
        "\t  np.mean(MMD_targeted[w_indx_targeted == 0]),\n",
        "\t file=open(filetxt, \"a\"))\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(6, 6))\n",
        "plt.hist(MMD_untargeted,bins=100, weights=100*np.ones(len(MMD_untargeted)) / len(MMD_untargeted))\n",
        "plt.xlabel(\"MMD_untargeted\")\n",
        "plt.ylabel(\"% of images\")\n",
        "plt.title('Histogram of MMD_untargeted')\n",
        "plt.axvline(np.mean(MMD_untargeted), color='k', linestyle='dashed', linewidth=1)\n",
        "plt.savefig(FOLDER+'hist_untargeted.png')\n",
        "# plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(6, 6))\n",
        "plt.hist(MMD_targeted,bins=100, weights=100*np.ones(len(MMD_targeted)) / len(MMD_targeted))\n",
        "plt.xlabel(\"MMD_targeted\")\n",
        "plt.ylabel(\"% of images\")\n",
        "plt.title('Histogram of MMD_targeted')\n",
        "plt.axvline(np.mean(MMD_untargeted), color='k', linestyle='dashed', linewidth=1)\n",
        "plt.savefig(FOLDER+'hist_targeted.png')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# In[183]:\n",
        "\n",
        "\n",
        "# if use_cuda:\n",
        "# \tcln_data = cln_data.cpu()\n",
        "# \ttrue_label = true_label.cpu()\n",
        "# \tadv_untargeted = adv_untargeted.cpu()\n",
        "# \tadv_targeted = adv_targeted.cpu()\n",
        "\t\n",
        "\n",
        "\n",
        "# %%\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAYlQGGoD2qC"
      },
      "source": [
        "####################################\n",
        "# imshow func\n",
        "####################################\n",
        "def imshow(img):\n",
        "  img = img.cpu()\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def _imshow(img):\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "\t# imshow(torchvision.utils.make_grid(img, normalize=True))\n",
        "\n",
        "  plt.imshow(torchvision.utils.make_grid(\n",
        "        img, normalize=True).numpy().transpose((1, 2, 0)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TabError",
          "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-49-3850063ba5d1>, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-3850063ba5d1>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    imshow(torchvision.utils.make_grid(img, normalize=True))\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "6SDVfIlcn136",
        "outputId": "c41d2152-4c15-47a2-bf01-c9cfef3ca4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for ii in range(num_plots):\n",
        "    \n",
        "    print(pred_cln[ii])\n",
        "\n",
        "_imshow(cln_data[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n6\n4\n6\n4\n9\n4\n4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmoo7Jsxn14G",
        "outputId": "601e8c44-34f2-41e1-e98e-e26e461e9bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "num_plots = 8\n",
        "#print(classes, pred_cln[ii])\n",
        "for jj in range(num_plots):\n",
        "\n",
        "\tii = good_samples[jj]\n",
        "\n",
        "\tplt.subplot(3, num_plots, jj + 1)\n",
        "\t_imshow(cln_data[ii])\n",
        "\tplt.title(\"clean \\n pred: {}\".format(classes[pred_cln[ii]]))\n",
        "\tplt.subplot(3, num_plots, jj + 1 + num_plots)\n",
        "\t_imshow(adv_untargeted[ii])\n",
        "\tplt.title(\"untargeted \\n adv \\n pred: {}\".format(classes[pred_untargeted_adv[ii]]))\n",
        "\tplt.subplot(3, num_plots, jj + 1 + num_plots * 2)\n",
        "\t_imshow(adv_targeted[ii])\n",
        "\tplt.title(\"target cat \\n adv \\n pred: {}\".format(classes[pred_targeted_adv[ii]]))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FOLDER+'test.png')\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l835YfXHn14L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}